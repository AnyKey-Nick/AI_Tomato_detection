{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5397bf2e-a0d9-4fc7-a511-d5745d64f7b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: roboflow in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.1.61)\n",
      "Requirement already satisfied: ultralytics in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (8.3.111)\n",
      "Requirement already satisfied: opencv-python in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (4.11.0.86)\n",
      "Requirement already satisfied: pytesseract in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (0.3.13)\n",
      "Requirement already satisfied: pandas in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (2.2.3)\n",
      "Requirement already satisfied: easyocr in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (1.7.2)\n",
      "Requirement already satisfied: certifi in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (2025.1.31)\n",
      "Requirement already satisfied: idna==3.7 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (3.7)\n",
      "Requirement already satisfied: cycler in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (0.12.1)\n",
      "Requirement already satisfied: kiwisolver>=1.3.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (1.4.7)\n",
      "Requirement already satisfied: matplotlib in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (3.9.4)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (2.0.2)\n",
      "Requirement already satisfied: opencv-python-headless==4.10.0.84 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (4.10.0.84)\n",
      "Requirement already satisfied: Pillow>=7.1.2 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (11.2.1)\n",
      "Requirement already satisfied: pillow-heif>=0.18.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (0.22.0)\n",
      "Requirement already satisfied: python-dateutil in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from roboflow) (2.9.0.post0)\n",
      "Requirement already satisfied: python-dotenv in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (1.1.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (2.32.3)\n",
      "Requirement already satisfied: six in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from roboflow) (1.17.0)\n",
      "Requirement already satisfied: urllib3>=1.26.6 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (2.4.0)\n",
      "Requirement already satisfied: tqdm>=4.41.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (4.67.1)\n",
      "Requirement already satisfied: PyYAML>=5.3.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (6.0.2)\n",
      "Requirement already satisfied: requests-toolbelt in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (1.0.0)\n",
      "Requirement already satisfied: filetype in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from roboflow) (1.2.0)\n",
      "Requirement already satisfied: scipy>=1.4.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (1.13.1)\n",
      "Requirement already satisfied: torch>=1.8.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (2.5.1+cu121)\n",
      "Requirement already satisfied: torchvision>=0.9.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (0.20.1+cu121)\n",
      "Requirement already satisfied: psutil in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from ultralytics) (7.0.0)\n",
      "Requirement already satisfied: py-cpuinfo in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (9.0.0)\n",
      "Requirement already satisfied: seaborn>=0.11.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (0.13.2)\n",
      "Requirement already satisfied: ultralytics-thop>=2.0.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from ultralytics) (2.0.14)\n",
      "Requirement already satisfied: packaging>=21.3 in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from pytesseract) (25.0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: scikit-image in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from easyocr) (0.24.0)\n",
      "Requirement already satisfied: python-bidi in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from easyocr) (0.6.6)\n",
      "Requirement already satisfied: Shapely in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from easyocr) (2.0.7)\n",
      "Requirement already satisfied: pyclipper in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from easyocr) (1.3.0.post6)\n",
      "Requirement already satisfied: ninja in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from easyocr) (1.11.1.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->roboflow) (1.3.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->roboflow) (4.57.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->roboflow) (3.2.3)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from matplotlib->roboflow) (6.5.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from requests->roboflow) (3.4.1)\n",
      "Requirement already satisfied: filelock in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.18.0)\n",
      "Requirement already satisfied: typing-extensions>=4.8.0 in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from torch>=1.8.0->ultralytics) (4.13.2)\n",
      "Requirement already satisfied: networkx in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (3.1.6)\n",
      "Requirement already satisfied: fsspec in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (2025.3.2)\n",
      "Requirement already satisfied: sympy==1.13.1 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from torch>=1.8.0->ultralytics) (1.13.1)\n",
      "Requirement already satisfied: mpmath<1.4,>=1.1.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from sympy==1.13.1->torch>=1.8.0->ultralytics) (1.3.0)\n",
      "Requirement already satisfied: colorama in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from tqdm>=4.41.0->roboflow) (0.4.6)\n",
      "Requirement already satisfied: imageio>=2.33 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->easyocr) (2.37.0)\n",
      "Requirement already satisfied: tifffile>=2022.8.12 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->easyocr) (2024.8.30)\n",
      "Requirement already satisfied: lazy-loader>=0.4 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from scikit-image->easyocr) (0.4)\n",
      "Requirement already satisfied: zipp>=3.1.0 in c:\\users\\ki7\\appdata\\roaming\\python\\python39\\site-packages (from importlib-resources>=3.2.0->matplotlib->roboflow) (3.21.0)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\ki7\\appdata\\local\\programs\\python\\python39\\lib\\site-packages (from jinja2->torch>=1.8.0->ultralytics) (3.0.2)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install roboflow ultralytics opencv-python pytesseract pandas easyocr\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "88403661-7081-4bb7-9967-cf8927f1e343",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "import pytesseract\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "from ultralytics import YOLO\n",
    "from roboflow import Roboflow\n",
    "import os\n",
    "import random\n",
    "import shutil\n",
    "import easyocr\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "09c03211-41f9-4d1d-97ab-1b5aaa618777",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading Roboflow workspace...\n",
      "loading Roboflow project...\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from roboflow import Roboflow\n",
    "rf = Roboflow(api_key=\"aJbnoNxtQRcb5jCA7zdh\")\n",
    "project = rf.workspace(\"tomatoes-xvztd\").project(\"tomates-cel5z\")\n",
    "version = project.version(10)\n",
    "dataset = version.download(\"yolov11\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "618b13ce-f94f-43ff-a23b-32cd78d4be2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dir = os.path.join(dataset.location, \"train\", \"images\")\n",
    "val_dir = os.path.join(dataset.location, \"valid\", \"images\")\n",
    "test_dir = os.path.join(dataset.location, \"test\", \"images\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b8cbcdd3-06e4-475d-a963-5eb1d231e062",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New https://pypi.org/project/ultralytics/8.3.115 available  Update with 'pip install -U ultralytics'\n",
      "Ultralytics 8.3.111  Python-3.9.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov10n.pt, data=C:\\Users\\Ki7\\Yolo\\tomates-10/data.yaml, epochs=100, time=None, patience=100, batch=16, imgsz=640, save=True, save_period=-1, cache=False, device=None, workers=8, project=None, name=train13, exist_ok=False, pretrained=True, optimizer=auto, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.01, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, cfg=None, tracker=botsort.yaml, save_dir=runs\\detect\\train13\n",
      "Overriding model.yaml nc=80 with nc=5\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1      9856  ultralytics.nn.modules.block.SCDown          [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1     36096  ultralytics.nn.modules.block.SCDown          [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1    249728  ultralytics.nn.modules.block.PSA             [256, 256]                    \n",
      " 11                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 12             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 13                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 14                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 15             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 16                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 17                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 18            [-1, 13]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 19                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 20                  -1  1     18048  ultralytics.nn.modules.block.SCDown          [128, 128, 3, 2]              \n",
      " 21            [-1, 10]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 22                  -1  1    282624  ultralytics.nn.modules.block.C2fCIB          [384, 256, 1, True, True]     \n",
      " 23        [16, 19, 22]  1    863278  ultralytics.nn.modules.head.v10Detect        [5, [64, 128, 256]]           \n",
      "YOLOv10n summary: 223 layers, 2,708,990 parameters, 2,708,974 gradients, 8.4 GFLOPs\n",
      "\n",
      "Transferred 493/595 items from pretrained weights\n",
      "Freezing layer 'model.23.dfl.conv.weight'\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mrunning Automatic Mixed Precision (AMP) checks...\n",
      "\u001b[34m\u001b[1mAMP: \u001b[0mchecks passed \n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mFast image access  (ping: 0.20.0 ms, read: 164.5197.5 MB/s, size: 468.5 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\Ki7\\Yolo\\tomates-10\\train\\labels.cache... 835 images, 1 backgrounds, 0 corrupt: 100%|█████████\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Box and segment counts should be equal, but got len(segments) = 930, len(boxes) = 1662. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mFast image access  (ping: 2.54.6 ms, read: 27.619.9 MB/s, size: 36.4 KB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\Ki7\\Yolo\\tomates-10\\valid\\labels.cache... 94 images, 0 backgrounds, 0 corrupt: 100%|██████████| \u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING  Box and segment counts should be equal, but got len(segments) = 147, len(boxes) = 186. To resolve this only boxes will be used and all segments will be removed. To avoid this please supply either a detect or segment dataset, not a detect-segment mixed dataset.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plotting labels to runs\\detect\\train13\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m 'optimizer=auto' found, ignoring 'lr0=0.01' and 'momentum=0.937' and determining best 'optimizer', 'lr0' and 'momentum' automatically... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m AdamW(lr=0.001111, momentum=0.9) with parameter groups 95 weight(decay=0.0), 108 weight(decay=0.0005), 107 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 8 dataloader workers\n",
      "Logging results to \u001b[1mruns\\detect\\train13\u001b[0m\n",
      "Starting training for 100 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      1/100      2.85G      1.801      7.829      2.548         12        640: 100%|██████████| 53/53 [00:50<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186    0.00553      0.716      0.119     0.0888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      2/100      2.82G       1.98        6.1      2.597          7        640: 100%|██████████| 53/53 [00:47<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.763      0.139      0.148      0.109\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      3/100      2.88G      2.099      5.444      2.636         10        640: 100%|██████████| 53/53 [00:46<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.692      0.218      0.242      0.177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      4/100      2.83G       2.06      4.996      2.619         15        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.615       0.27      0.254      0.191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      5/100       2.8G      2.127      4.461      2.657          9        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.642      0.212      0.257      0.198\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      6/100      2.86G      2.062       4.06      2.579         17        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.635      0.286      0.264      0.202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      7/100      2.83G      2.021      3.805      2.566          9        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.703      0.274      0.303      0.231\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      8/100       2.8G      2.024      3.502      2.559         17        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.787      0.256      0.466      0.355\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "      9/100      2.81G      1.942      3.229      2.508          7        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.705      0.295      0.324      0.256\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     10/100      2.93G      1.916      3.045       2.48         13        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.648      0.284      0.335       0.27\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     11/100      2.82G       2.01      3.028      2.504         22        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.577      0.344       0.41      0.342\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     12/100      2.84G      1.872      2.843      2.438         11        640: 100%|██████████| 53/53 [00:50<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.516      0.341      0.332      0.273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     13/100      2.79G      1.872      2.742      2.457         12        640: 100%|██████████| 53/53 [00:46<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.565      0.427        0.5      0.425\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     14/100      2.83G      1.811      2.654      2.448         23        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.729      0.243       0.36      0.293\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     15/100      2.84G      1.852      2.648      2.453          9        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.667       0.39      0.436      0.361\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     16/100      2.79G      1.888      2.585      2.444          7        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.645      0.415      0.464      0.395\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     17/100      2.84G      1.819      2.504      2.453         11        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.648      0.429      0.483      0.404\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     18/100      2.82G       1.82      2.387      2.446         10        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.523      0.479      0.496      0.422\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     19/100      2.84G      1.811      2.347      2.402         10        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.616        0.4      0.446      0.378\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     20/100      2.82G      1.824      2.337      2.417          8        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.578      0.563      0.595      0.502\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     21/100      2.79G      1.835       2.25      2.407         10        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.422      0.521      0.541      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     22/100      2.92G      1.769       2.17      2.392          6        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.505      0.565       0.57      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     23/100      2.84G      1.736      2.102      2.391          6        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.764      0.384      0.548      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     24/100      2.84G      1.757      2.171       2.39         14        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.441      0.571      0.569      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     25/100       2.8G      1.723      2.125      2.364          5        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.61      0.451       0.52      0.439\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     26/100      2.81G      1.727      2.062      2.356          9        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.681      0.385      0.511       0.44\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     27/100      2.82G      1.753      2.059      2.378         12        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.547      0.508      0.533      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     28/100      2.84G      1.665      2.085      2.322          4        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.481      0.543      0.507      0.438\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     29/100      2.87G      1.621      1.833       2.33          9        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.503      0.527      0.533      0.458\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     30/100      2.79G      1.686      1.993      2.352          8        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.473      0.595      0.532      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     31/100      2.85G       1.69      1.966      2.331         12        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.401      0.505      0.511      0.436\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     32/100      2.96G      1.644      1.902      2.301         11        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.587      0.506      0.532      0.466\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     33/100       2.8G       1.67      1.902      2.342          5        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.381      0.672      0.565      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     34/100      2.83G      1.675      1.916      2.326         15        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.419      0.587      0.536      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     35/100      2.79G      1.643       1.82      2.329          7        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.453       0.61       0.56      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     36/100      2.81G      1.663       1.94      2.302         13        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.532      0.645       0.57      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     37/100      2.84G      1.613      1.877      2.312          4        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.482      0.589        0.5      0.437\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     38/100      2.85G      1.624      1.763      2.272          4        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186        0.4      0.668      0.566      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     39/100      2.83G      1.582      1.767      2.303          7        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.368      0.618      0.519      0.443\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     40/100      2.81G      1.592      1.702      2.293         10        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.495      0.578      0.562      0.485\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     41/100      2.82G      1.648      1.768      2.299         21        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.446      0.647      0.521      0.453\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     42/100      2.81G      1.562      1.701      2.246         11        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.468      0.593      0.543      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     43/100      2.83G      1.577       1.69      2.273         18        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.43      0.563      0.503       0.43\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     44/100      2.83G      1.521       1.67      2.283         10        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.501      0.489      0.535      0.456\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     45/100       2.8G      1.497       1.59       2.24         13        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.413      0.586      0.556       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     46/100       2.8G      1.574      1.658      2.261          6        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.408      0.709      0.572       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     47/100      2.84G      1.499      1.606      2.215         11        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.522      0.572      0.546      0.476\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     48/100      2.84G      1.476       1.56      2.223         11        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.426      0.628      0.523       0.45\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     49/100      2.79G      1.564      1.679      2.234         14        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.403      0.633      0.559      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     50/100       2.8G       1.56      1.602      2.247         20        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.433      0.687      0.557      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     51/100      2.82G      1.499      1.668      2.241          5        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.338      0.486      0.551      0.484\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     52/100      2.84G      1.518      1.583      2.226         26        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.608      0.554      0.622      0.541\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     53/100      2.91G      1.485      1.508      2.218         11        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.47      0.533      0.548      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     54/100       2.8G      1.503       1.53      2.219         17        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.47      0.547      0.552      0.475\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     55/100      2.84G      1.496      1.496      2.221          8        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.457      0.643      0.579      0.503\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     56/100      2.83G      1.492      1.497      2.203         32        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.472      0.679       0.54      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     57/100      2.84G      1.459       1.46      2.178         13        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.488      0.682      0.573      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     58/100      2.92G      1.471      1.556      2.191          8        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.42       0.58      0.546       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     59/100      2.84G      1.552      1.544      2.226          4        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.463      0.667      0.572      0.498\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     60/100      2.84G      1.441       1.54       2.23          4        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.516      0.606       0.58      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     61/100      2.84G      1.496      1.453       2.22         10        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.405      0.632      0.503      0.427\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     62/100      2.82G       1.41      1.394      2.168         12        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.393      0.511      0.576      0.508\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     63/100      2.83G      1.366      1.352      2.161          4        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.498      0.575      0.576      0.506\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     64/100      2.87G       1.43      1.362      2.188          8        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.524      0.628      0.609      0.529\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     65/100      2.84G      1.427      1.376      2.164          8        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.508      0.595      0.599      0.513\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     66/100      2.83G      1.414      1.332      2.151         11        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.486      0.612      0.594      0.507\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     67/100      2.79G      1.395      1.312      2.147          5        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.473      0.656      0.572      0.494\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     68/100      2.81G      1.445      1.377      2.199          4        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.388      0.614      0.532      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     69/100      2.81G      1.417      1.349      2.175         13        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.375      0.635      0.554      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     70/100      2.81G      1.351      1.304      2.153         10        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.463      0.589      0.562      0.495\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     71/100      2.88G      1.284      1.275      2.088         22        640: 100%|██████████| 53/53 [00:46<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.474      0.614      0.609       0.53\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     72/100      2.87G      1.359       1.28      2.146          5        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.422      0.609       0.55      0.474\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     73/100      2.95G      1.325      1.222      2.115         14        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.434      0.544      0.553      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     74/100      2.82G      1.362      1.335      2.152          7        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.458      0.588      0.572      0.493\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     75/100      2.84G       1.31      1.278       2.09         13        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.468      0.597      0.531       0.46\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     76/100      2.83G      1.317      1.229      2.139          6        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.51      0.509      0.525      0.463\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     77/100      2.81G       1.32      1.231      2.104          6        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186       0.46      0.566      0.541      0.469\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     78/100      2.82G       1.35      1.259      2.094         42        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.462      0.559      0.551      0.482\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     79/100      2.81G       1.38      1.242      2.161         25        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.434      0.582      0.554      0.481\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     80/100      2.85G      1.309      1.189      2.085         12        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.505      0.591      0.578       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     81/100      2.84G      1.336      1.232      2.153          7        640: 100%|██████████| 53/53 [00:46<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.479      0.668      0.588      0.517\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     82/100      2.82G      1.274      1.138      2.094          7        640: 100%|██████████| 53/53 [00:46<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.491      0.658      0.598      0.522\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     83/100      2.82G      1.252      1.118      2.081         12        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.498      0.688      0.588      0.518\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     84/100      2.84G      1.301      1.166      2.097         14        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.524       0.67      0.581      0.512\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     85/100      2.81G      1.302      1.166      2.124         13        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.526      0.647      0.569      0.497\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     86/100      2.83G      1.287      1.194       2.09          9        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.491      0.605      0.544      0.479\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     87/100      2.88G      1.224      1.099      2.079         15        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.476      0.535      0.542      0.473\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     88/100      2.83G      1.246      1.123      2.082         11        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.467      0.623      0.576       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     89/100      2.84G      1.278      1.152      2.062          7        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.519      0.506      0.531      0.464\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     90/100      2.91G      1.273      1.131      2.086         10        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.516      0.547       0.56      0.488\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Closing dataloader mosaic\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     91/100      2.87G      1.077     0.9381      1.983          4        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.475      0.677      0.575       0.51\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     92/100       2.8G      1.061     0.8921      2.001          6        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.543      0.589      0.554      0.487\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     93/100       2.8G      1.065     0.8594      1.983          8        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.466      0.629      0.534      0.472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     94/100      2.81G      1.045     0.8468      2.006          3        640: 100%|██████████| 53/53 [00:45<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.513      0.609      0.543       0.48\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     95/100      2.81G      1.033     0.8283      1.994         13        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.497       0.65      0.559      0.489\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     96/100      2.87G      1.051     0.8133      1.982          3        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.532      0.637      0.553      0.483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     97/100       2.8G       1.06     0.8835      1.987          3        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.534      0.662      0.569      0.504\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     98/100      2.82G       1.01     0.8097       1.97          3        640: 100%|██████████| 53/53 [00:43<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:01<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.518      0.674      0.551      0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "     99/100      2.83G      1.023     0.8014      1.965          3        640: 100%|██████████| 53/53 [00:44<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.479      0.618      0.544      0.478\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "    100/100      2.81G      1.028     0.8187      1.974          8        640: 100%|██████████| 53/53 [00:49<00:00,  1.\n",
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.498       0.64      0.556       0.49\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "100 epochs completed in 1.358 hours.\n",
      "Optimizer stripped from runs\\detect\\train13\\weights\\last.pt, 5.8MB\n",
      "Optimizer stripped from runs\\detect\\train13\\weights\\best.pt, 5.8MB\n",
      "\n",
      "Validating runs\\detect\\train13\\weights\\best.pt...\n",
      "Ultralytics 8.3.111  Python-3.9.0 torch-2.5.1+cu121 CUDA:0 (NVIDIA GeForce GTX 1050 Ti, 4096MiB)\n",
      "YOLOv10n summary (fused): 102 layers, 2,266,143 parameters, 0 gradients, 6.5 GFLOPs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                 Class     Images  Instances      Box(P          R      mAP50  mAP50-95): 100%|██████████| 3/3 [00:02<0\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                   all         94        186      0.608      0.552      0.622      0.541\n",
      "            good_10_40          8          8      0.825      0.596      0.729      0.657\n",
      "            good_40_70          4          4      0.546        0.5      0.524      0.501\n",
      "               healthy         41        103      0.655      0.646      0.722      0.583\n",
      "                unripe          7         21      0.251      0.319      0.291      0.227\n",
      "                rotten         42         50      0.765        0.7      0.843       0.74\n",
      "Speed: 0.5ms preprocess, 10.1ms inference, 0.0ms loss, 0.7ms postprocess per image\n",
      "Results saved to \u001b[1mruns\\detect\\train13\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "model = YOLO(\"yolov10n.pt\")\n",
    "results = model.train(data=dataset.location + \"/data.yaml\", epochs=100, imgsz=640)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6c50dc59-b989-4831-9414-0df6e7bd3811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 384x640 4 healthys, 5 unripes, 87.2ms\n",
      "Speed: 5.4ms preprocess, 87.2ms inference, 2.4ms postprocess per image at shape (1, 3, 384, 640)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from ultralytics import YOLO\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "# Завантаж свою модель\n",
    "model = YOLO(\"C:/Users/Ki7/Yolo/runs/detect/train13/weights/best.pt\") \n",
    "\n",
    "# Вкажи шлях до фото\n",
    "image_path = \"C:/Users/Ki7/Yolo/Tomato1.jpeg\"\n",
    "\n",
    "# Завантаж зображення\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "# Перевір, що зображення не порожнє\n",
    "assert image is not None, \"Зображення не знайдено!\"\n",
    "\n",
    "# Отримай результати\n",
    "results = model(image)\n",
    "\n",
    "# Вивести з результатами прямо в новий кадр\n",
    "annotated_frame = results[0].plot()  # автоматично малює прямокутники\n",
    "\n",
    "# Зберегти зображення з результатами\n",
    "cv2.imwrite(\"C:/Users/Ki7/Yolo/photo_with_boxes2.jpg\", annotated_frame)\n",
    "\n",
    "# Або показати прямо в ноутбуці\n",
    "plt.imshow(cv2.cvtColor(annotated_frame, cv2.COLOR_BGR2RGB))\n",
    "plt.axis(\"off\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be9e36d9-a77e-4c97-8717-a43611d7ef0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 480x640 (no detections), 88.7ms\n",
      "Speed: 6.8ms preprocess, 88.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 48.3ms\n",
      "Speed: 4.3ms preprocess, 48.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 31.3ms\n",
      "Speed: 3.5ms preprocess, 31.3ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 49.8ms\n",
      "Speed: 4.3ms preprocess, 49.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 39.4ms\n",
      "Speed: 3.8ms preprocess, 39.4ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.4ms\n",
      "Speed: 5.2ms preprocess, 32.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.7ms\n",
      "Speed: 4.9ms preprocess, 30.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.8ms\n",
      "Speed: 5.3ms preprocess, 44.8ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.5ms\n",
      "Speed: 3.4ms preprocess, 28.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 44.4ms\n",
      "Speed: 2.9ms preprocess, 44.4ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 31.0ms\n",
      "Speed: 5.2ms preprocess, 31.0ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 37.2ms\n",
      "Speed: 5.2ms preprocess, 37.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 36.9ms\n",
      "Speed: 3.8ms preprocess, 36.9ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.8ms\n",
      "Speed: 3.8ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 35.6ms\n",
      "Speed: 5.1ms preprocess, 35.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.8ms\n",
      "Speed: 5.5ms preprocess, 32.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 36.6ms\n",
      "Speed: 4.2ms preprocess, 36.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.2ms\n",
      "Speed: 2.6ms preprocess, 29.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.1ms\n",
      "Speed: 2.8ms preprocess, 30.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 33.5ms\n",
      "Speed: 4.9ms preprocess, 33.5ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.7ms\n",
      "Speed: 4.1ms preprocess, 25.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.4ms\n",
      "Speed: 3.0ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 33.7ms\n",
      "Speed: 2.8ms preprocess, 33.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.2ms\n",
      "Speed: 3.3ms preprocess, 32.2ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.4ms\n",
      "Speed: 2.9ms preprocess, 28.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.6ms\n",
      "Speed: 4.1ms preprocess, 30.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 36.5ms\n",
      "Speed: 5.3ms preprocess, 36.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 33.1ms\n",
      "Speed: 4.6ms preprocess, 33.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.3ms\n",
      "Speed: 3.8ms preprocess, 26.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.1ms\n",
      "Speed: 3.9ms preprocess, 27.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 37.1ms\n",
      "Speed: 2.6ms preprocess, 37.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.4ms\n",
      "Speed: 3.1ms preprocess, 27.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.8ms\n",
      "Speed: 3.2ms preprocess, 32.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 34.7ms\n",
      "Speed: 3.8ms preprocess, 34.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 33.6ms\n",
      "Speed: 3.3ms preprocess, 33.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.2ms\n",
      "Speed: 2.6ms preprocess, 24.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 26.0ms\n",
      "Speed: 4.9ms preprocess, 26.0ms inference, 4.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 34.0ms\n",
      "Speed: 3.6ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 35.0ms\n",
      "Speed: 3.0ms preprocess, 35.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.4ms\n",
      "Speed: 2.6ms preprocess, 26.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.2ms\n",
      "Speed: 3.3ms preprocess, 27.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.4ms\n",
      "Speed: 4.2ms preprocess, 26.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 26.2ms\n",
      "Speed: 2.6ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 24.7ms\n",
      "Speed: 4.2ms preprocess, 24.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.6ms\n",
      "Speed: 4.3ms preprocess, 28.6ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 32.1ms\n",
      "Speed: 2.7ms preprocess, 32.1ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.3ms\n",
      "Speed: 2.8ms preprocess, 27.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 29.2ms\n",
      "Speed: 5.0ms preprocess, 29.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 37.9ms\n",
      "Speed: 3.1ms preprocess, 37.9ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 32.1ms\n",
      "Speed: 2.8ms preprocess, 32.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 24.7ms\n",
      "Speed: 3.2ms preprocess, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 27.1ms\n",
      "Speed: 2.9ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 30.6ms\n",
      "Speed: 3.6ms preprocess, 30.6ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 26.6ms\n",
      "Speed: 4.5ms preprocess, 26.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 29.8ms\n",
      "Speed: 3.9ms preprocess, 29.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 25.7ms\n",
      "Speed: 4.6ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.1ms\n",
      "Speed: 2.5ms preprocess, 38.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.4ms\n",
      "Speed: 5.2ms preprocess, 28.4ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.4ms\n",
      "Speed: 3.9ms preprocess, 27.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 35.9ms\n",
      "Speed: 3.2ms preprocess, 35.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.4ms\n",
      "Speed: 3.9ms preprocess, 29.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 32.5ms\n",
      "Speed: 4.5ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 32.8ms\n",
      "Speed: 4.2ms preprocess, 32.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 34.3ms\n",
      "Speed: 3.5ms preprocess, 34.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 31.0ms\n",
      "Speed: 2.8ms preprocess, 31.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.3ms\n",
      "Speed: 3.1ms preprocess, 25.3ms inference, 1.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 26.6ms\n",
      "Speed: 3.0ms preprocess, 26.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.2ms\n",
      "Speed: 2.7ms preprocess, 25.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 28.4ms\n",
      "Speed: 4.0ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 35.4ms\n",
      "Speed: 4.0ms preprocess, 35.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 34.4ms\n",
      "Speed: 4.3ms preprocess, 34.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 26.3ms\n",
      "Speed: 4.6ms preprocess, 26.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 34.8ms\n",
      "Speed: 8.5ms preprocess, 34.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.0ms\n",
      "Speed: 2.9ms preprocess, 27.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.8ms\n",
      "Speed: 2.9ms preprocess, 30.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 24.0ms\n",
      "Speed: 4.2ms preprocess, 24.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 27.6ms\n",
      "Speed: 2.8ms preprocess, 27.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.8ms\n",
      "Speed: 2.9ms preprocess, 26.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 30.1ms\n",
      "Speed: 5.2ms preprocess, 30.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 24.4ms\n",
      "Speed: 2.8ms preprocess, 24.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 27.8ms\n",
      "Speed: 5.7ms preprocess, 27.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 26.4ms\n",
      "Speed: 4.0ms preprocess, 26.4ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 25.9ms\n",
      "Speed: 3.9ms preprocess, 25.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 29.9ms\n",
      "Speed: 2.8ms preprocess, 29.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.7ms\n",
      "Speed: 5.3ms preprocess, 29.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 30.9ms\n",
      "Speed: 4.5ms preprocess, 30.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 27.5ms\n",
      "Speed: 3.0ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 34.5ms\n",
      "Speed: 4.3ms preprocess, 34.5ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 43.0ms\n",
      "Speed: 4.3ms preprocess, 43.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 35.5ms\n",
      "Speed: 3.2ms preprocess, 35.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 36.1ms\n",
      "Speed: 5.9ms preprocess, 36.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 43.5ms\n",
      "Speed: 4.4ms preprocess, 43.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 37.4ms\n",
      "Speed: 4.2ms preprocess, 37.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 36.4ms\n",
      "Speed: 3.9ms preprocess, 36.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 38.4ms\n",
      "Speed: 5.0ms preprocess, 38.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 41.0ms\n",
      "Speed: 5.1ms preprocess, 41.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 34.3ms\n",
      "Speed: 5.4ms preprocess, 34.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 43.7ms\n",
      "Speed: 3.9ms preprocess, 43.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 34.3ms\n",
      "Speed: 3.8ms preprocess, 34.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 32.6ms\n",
      "Speed: 2.9ms preprocess, 32.6ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 38.8ms\n",
      "Speed: 4.3ms preprocess, 38.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 36.6ms\n",
      "Speed: 2.9ms preprocess, 36.6ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 30.0ms\n",
      "Speed: 3.9ms preprocess, 30.0ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 72.1ms\n",
      "Speed: 3.4ms preprocess, 72.1ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 78.7ms\n",
      "Speed: 5.2ms preprocess, 78.7ms inference, 12.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 107.7ms\n",
      "Speed: 5.1ms preprocess, 107.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 62.7ms\n",
      "Speed: 4.5ms preprocess, 62.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 53.8ms\n",
      "Speed: 5.0ms preprocess, 53.8ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 55.5ms\n",
      "Speed: 4.7ms preprocess, 55.5ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 68.5ms\n",
      "Speed: 4.5ms preprocess, 68.5ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 64.3ms\n",
      "Speed: 4.7ms preprocess, 64.3ms inference, 4.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 59.0ms\n",
      "Speed: 5.1ms preprocess, 59.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 43.7ms\n",
      "Speed: 5.2ms preprocess, 43.7ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 51.8ms\n",
      "Speed: 5.9ms preprocess, 51.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 48.1ms\n",
      "Speed: 5.2ms preprocess, 48.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 44.5ms\n",
      "Speed: 3.5ms preprocess, 44.5ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 46.2ms\n",
      "Speed: 3.7ms preprocess, 46.2ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 58.7ms\n",
      "Speed: 4.4ms preprocess, 58.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 40.8ms\n",
      "Speed: 5.3ms preprocess, 40.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.8ms\n",
      "Speed: 4.3ms preprocess, 38.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 42.1ms\n",
      "Speed: 4.0ms preprocess, 42.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 43.1ms\n",
      "Speed: 4.4ms preprocess, 43.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 32.9ms\n",
      "Speed: 4.3ms preprocess, 32.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 37.5ms\n",
      "Speed: 5.1ms preprocess, 37.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 36.3ms\n",
      "Speed: 3.2ms preprocess, 36.3ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 33.5ms\n",
      "Speed: 3.5ms preprocess, 33.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 45.4ms\n",
      "Speed: 3.5ms preprocess, 45.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 40.2ms\n",
      "Speed: 4.1ms preprocess, 40.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 64.6ms\n",
      "Speed: 6.5ms preprocess, 64.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 34.7ms\n",
      "Speed: 4.4ms preprocess, 34.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.2ms\n",
      "Speed: 3.6ms preprocess, 38.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.0ms\n",
      "Speed: 4.0ms preprocess, 38.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 35.0ms\n",
      "Speed: 5.4ms preprocess, 35.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 33.7ms\n",
      "Speed: 3.4ms preprocess, 33.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 37.8ms\n",
      "Speed: 3.4ms preprocess, 37.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.0ms\n",
      "Speed: 2.8ms preprocess, 26.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.5ms\n",
      "Speed: 3.7ms preprocess, 28.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 37.9ms\n",
      "Speed: 4.6ms preprocess, 37.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 30.3ms\n",
      "Speed: 3.5ms preprocess, 30.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 48.7ms\n",
      "Speed: 11.2ms preprocess, 48.7ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 41.8ms\n",
      "Speed: 5.2ms preprocess, 41.8ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.4ms\n",
      "Speed: 5.5ms preprocess, 32.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.4ms\n",
      "Speed: 4.7ms preprocess, 27.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 46.4ms\n",
      "Speed: 4.6ms preprocess, 46.4ms inference, 3.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 49.9ms\n",
      "Speed: 4.6ms preprocess, 49.9ms inference, 3.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.6ms\n",
      "Speed: 4.5ms preprocess, 28.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.6ms\n",
      "Speed: 2.8ms preprocess, 27.6ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 36.2ms\n",
      "Speed: 3.7ms preprocess, 36.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 36.6ms\n",
      "Speed: 3.3ms preprocess, 36.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 34.7ms\n",
      "Speed: 3.2ms preprocess, 34.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 29.9ms\n",
      "Speed: 3.3ms preprocess, 29.9ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.2ms\n",
      "Speed: 3.1ms preprocess, 25.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.3ms\n",
      "Speed: 4.2ms preprocess, 28.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 23.8ms\n",
      "Speed: 2.9ms preprocess, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.8ms\n",
      "Speed: 2.8ms preprocess, 23.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 25.9ms\n",
      "Speed: 3.5ms preprocess, 25.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.6ms\n",
      "Speed: 2.8ms preprocess, 27.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.1ms\n",
      "Speed: 2.8ms preprocess, 27.1ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 34.5ms\n",
      "Speed: 3.6ms preprocess, 34.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.9ms\n",
      "Speed: 2.9ms preprocess, 27.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.9ms\n",
      "Speed: 3.8ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 34.0ms\n",
      "Speed: 2.8ms preprocess, 34.0ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 34.2ms\n",
      "Speed: 3.4ms preprocess, 34.2ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 43.9ms\n",
      "Speed: 3.6ms preprocess, 43.9ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 33.9ms\n",
      "Speed: 4.1ms preprocess, 33.9ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 37.1ms\n",
      "Speed: 4.2ms preprocess, 37.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 26.8ms\n",
      "Speed: 3.5ms preprocess, 26.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 41.4ms\n",
      "Speed: 4.9ms preprocess, 41.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 45.3ms\n",
      "Speed: 4.6ms preprocess, 45.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 35.6ms\n",
      "Speed: 4.2ms preprocess, 35.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 30.2ms\n",
      "Speed: 3.1ms preprocess, 30.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.2ms\n",
      "Speed: 3.2ms preprocess, 25.2ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 29.5ms\n",
      "Speed: 3.0ms preprocess, 29.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 30.1ms\n",
      "Speed: 3.7ms preprocess, 30.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 33.4ms\n",
      "Speed: 3.2ms preprocess, 33.4ms inference, 3.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 32.2ms\n",
      "Speed: 3.9ms preprocess, 32.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 35.1ms\n",
      "Speed: 3.9ms preprocess, 35.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.2ms\n",
      "Speed: 2.9ms preprocess, 22.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.1ms\n",
      "Speed: 2.6ms preprocess, 23.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 21.2ms\n",
      "Speed: 2.8ms preprocess, 21.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 20.9ms\n",
      "Speed: 3.0ms preprocess, 20.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 27.1ms\n",
      "Speed: 2.8ms preprocess, 27.1ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.8ms\n",
      "Speed: 3.0ms preprocess, 22.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 28.1ms\n",
      "Speed: 2.9ms preprocess, 28.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.7ms\n",
      "Speed: 3.0ms preprocess, 21.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 26.4ms\n",
      "Speed: 2.8ms preprocess, 26.4ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 31.6ms\n",
      "Speed: 3.4ms preprocess, 31.6ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 23.9ms\n",
      "Speed: 3.0ms preprocess, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 31.1ms\n",
      "Speed: 3.6ms preprocess, 31.1ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 35.4ms\n",
      "Speed: 3.9ms preprocess, 35.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 26.7ms\n",
      "Speed: 3.3ms preprocess, 26.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 33.9ms\n",
      "Speed: 3.1ms preprocess, 33.9ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 26.2ms\n",
      "Speed: 3.6ms preprocess, 26.2ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 37.5ms\n",
      "Speed: 3.7ms preprocess, 37.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 33.3ms\n",
      "Speed: 3.2ms preprocess, 33.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 35.5ms\n",
      "Speed: 3.0ms preprocess, 35.5ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.3ms\n",
      "Speed: 4.1ms preprocess, 29.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.1ms\n",
      "Speed: 3.7ms preprocess, 28.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 36.9ms\n",
      "Speed: 4.2ms preprocess, 36.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 29.6ms\n",
      "Speed: 2.9ms preprocess, 29.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.9ms\n",
      "Speed: 3.5ms preprocess, 26.9ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 30.8ms\n",
      "Speed: 3.2ms preprocess, 30.8ms inference, 2.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 40.5ms\n",
      "Speed: 4.1ms preprocess, 40.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 34.3ms\n",
      "Speed: 3.9ms preprocess, 34.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.7ms\n",
      "Speed: 3.7ms preprocess, 30.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 43.6ms\n",
      "Speed: 3.8ms preprocess, 43.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.0ms\n",
      "Speed: 2.9ms preprocess, 32.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.4ms\n",
      "Speed: 3.2ms preprocess, 31.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 36.4ms\n",
      "Speed: 3.5ms preprocess, 36.4ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.4ms\n",
      "Speed: 3.3ms preprocess, 28.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.4ms\n",
      "Speed: 3.7ms preprocess, 26.4ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.3ms\n",
      "Speed: 3.6ms preprocess, 26.3ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.3ms\n",
      "Speed: 3.0ms preprocess, 31.3ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 45.1ms\n",
      "Speed: 3.7ms preprocess, 45.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 36.7ms\n",
      "Speed: 3.8ms preprocess, 36.7ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 37.6ms\n",
      "Speed: 3.7ms preprocess, 37.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 35.1ms\n",
      "Speed: 3.4ms preprocess, 35.1ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 41.3ms\n",
      "Speed: 3.9ms preprocess, 41.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 32.4ms\n",
      "Speed: 3.3ms preprocess, 32.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.2ms\n",
      "Speed: 3.0ms preprocess, 21.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 20.5ms\n",
      "Speed: 3.0ms preprocess, 20.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 24.6ms\n",
      "Speed: 2.9ms preprocess, 24.6ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.1ms\n",
      "Speed: 3.9ms preprocess, 28.1ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 33.6ms\n",
      "Speed: 4.0ms preprocess, 33.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 36.3ms\n",
      "Speed: 3.9ms preprocess, 36.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 31.3ms\n",
      "Speed: 4.0ms preprocess, 31.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.8ms\n",
      "Speed: 4.0ms preprocess, 29.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.1ms\n",
      "Speed: 3.2ms preprocess, 21.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.0ms\n",
      "Speed: 3.2ms preprocess, 28.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.1ms\n",
      "Speed: 3.5ms preprocess, 23.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 38.3ms\n",
      "Speed: 7.8ms preprocess, 38.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 24.3ms\n",
      "Speed: 3.2ms preprocess, 24.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 24.7ms\n",
      "Speed: 3.1ms preprocess, 24.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 28.3ms\n",
      "Speed: 3.8ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 31.0ms\n",
      "Speed: 3.6ms preprocess, 31.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 30.3ms\n",
      "Speed: 3.6ms preprocess, 30.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 26.7ms\n",
      "Speed: 2.9ms preprocess, 26.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 28.0ms\n",
      "Speed: 3.4ms preprocess, 28.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 27.1ms\n",
      "Speed: 4.2ms preprocess, 27.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.6ms\n",
      "Speed: 3.3ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.8ms\n",
      "Speed: 3.4ms preprocess, 23.8ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.1ms\n",
      "Speed: 3.6ms preprocess, 23.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.4ms\n",
      "Speed: 2.9ms preprocess, 21.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 22.8ms\n",
      "Speed: 3.5ms preprocess, 22.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.0ms\n",
      "Speed: 3.1ms preprocess, 28.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.5ms\n",
      "Speed: 3.0ms preprocess, 21.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.0ms\n",
      "Speed: 2.9ms preprocess, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 22.2ms\n",
      "Speed: 3.8ms preprocess, 22.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 27.9ms\n",
      "Speed: 4.5ms preprocess, 27.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.9ms\n",
      "Speed: 3.2ms preprocess, 29.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.3ms\n",
      "Speed: 3.7ms preprocess, 23.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.0ms\n",
      "Speed: 2.9ms preprocess, 23.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.8ms\n",
      "Speed: 4.2ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.8ms\n",
      "Speed: 3.1ms preprocess, 23.8ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 27.7ms\n",
      "Speed: 3.1ms preprocess, 27.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.9ms\n",
      "Speed: 4.2ms preprocess, 28.9ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.1ms\n",
      "Speed: 3.3ms preprocess, 25.1ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 24.2ms\n",
      "Speed: 3.1ms preprocess, 24.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.8ms\n",
      "Speed: 4.2ms preprocess, 27.8ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.8ms\n",
      "Speed: 4.2ms preprocess, 29.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 35.0ms\n",
      "Speed: 3.1ms preprocess, 35.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.1ms\n",
      "Speed: 4.2ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.7ms\n",
      "Speed: 3.8ms preprocess, 27.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.9ms\n",
      "Speed: 3.2ms preprocess, 26.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.3ms\n",
      "Speed: 4.3ms preprocess, 22.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.8ms\n",
      "Speed: 3.1ms preprocess, 21.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 34.9ms\n",
      "Speed: 3.4ms preprocess, 34.9ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 26.1ms\n",
      "Speed: 2.8ms preprocess, 26.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.6ms\n",
      "Speed: 3.1ms preprocess, 28.6ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.3ms\n",
      "Speed: 3.8ms preprocess, 28.3ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.4ms\n",
      "Speed: 3.8ms preprocess, 22.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.4ms\n",
      "Speed: 3.4ms preprocess, 21.4ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 22.9ms\n",
      "Speed: 2.9ms preprocess, 22.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 27.5ms\n",
      "Speed: 2.9ms preprocess, 27.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.8ms\n",
      "Speed: 3.8ms preprocess, 25.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 29.9ms\n",
      "Speed: 4.1ms preprocess, 29.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.2ms\n",
      "Speed: 3.3ms preprocess, 25.2ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 30.4ms\n",
      "Speed: 3.7ms preprocess, 30.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 28.3ms\n",
      "Speed: 2.8ms preprocess, 28.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.7ms\n",
      "Speed: 3.7ms preprocess, 23.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 23.4ms\n",
      "Speed: 2.9ms preprocess, 23.4ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.5ms\n",
      "Speed: 4.2ms preprocess, 21.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.2ms\n",
      "Speed: 2.7ms preprocess, 28.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.6ms\n",
      "Speed: 2.7ms preprocess, 21.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 28.2ms\n",
      "Speed: 2.9ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 28.1ms\n",
      "Speed: 3.4ms preprocess, 28.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 20.6ms\n",
      "Speed: 3.4ms preprocess, 20.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 36.3ms\n",
      "Speed: 3.1ms preprocess, 36.3ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.2ms\n",
      "Speed: 3.0ms preprocess, 21.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.3ms\n",
      "Speed: 3.0ms preprocess, 21.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 24.3ms\n",
      "Speed: 3.2ms preprocess, 24.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 32.4ms\n",
      "Speed: 4.3ms preprocess, 32.4ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.8ms\n",
      "Speed: 3.1ms preprocess, 23.8ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.5ms\n",
      "Speed: 2.8ms preprocess, 21.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 33.0ms\n",
      "Speed: 3.5ms preprocess, 33.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 29.0ms\n",
      "Speed: 3.1ms preprocess, 29.0ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.9ms\n",
      "Speed: 2.9ms preprocess, 21.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 32.6ms\n",
      "Speed: 3.1ms preprocess, 32.6ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.7ms\n",
      "Speed: 3.0ms preprocess, 21.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.7ms\n",
      "Speed: 3.1ms preprocess, 21.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.4ms\n",
      "Speed: 3.1ms preprocess, 27.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 23.8ms\n",
      "Speed: 3.5ms preprocess, 23.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.6ms\n",
      "Speed: 3.3ms preprocess, 28.6ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 35.3ms\n",
      "Speed: 3.2ms preprocess, 35.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 22.0ms\n",
      "Speed: 3.3ms preprocess, 22.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.5ms\n",
      "Speed: 3.1ms preprocess, 21.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 23.7ms\n",
      "Speed: 2.9ms preprocess, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.3ms\n",
      "Speed: 3.1ms preprocess, 27.3ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 35.0ms\n",
      "Speed: 4.0ms preprocess, 35.0ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 33.0ms\n",
      "Speed: 3.6ms preprocess, 33.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 26.1ms\n",
      "Speed: 3.0ms preprocess, 26.1ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 27.2ms\n",
      "Speed: 3.3ms preprocess, 27.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 25.5ms\n",
      "Speed: 3.1ms preprocess, 25.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.1ms\n",
      "Speed: 3.1ms preprocess, 38.1ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 32.6ms\n",
      "Speed: 3.4ms preprocess, 32.6ms inference, 3.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 92.7ms\n",
      "Speed: 6.3ms preprocess, 92.7ms inference, 3.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 69.9ms\n",
      "Speed: 4.6ms preprocess, 69.9ms inference, 5.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 156.4ms\n",
      "Speed: 6.1ms preprocess, 156.4ms inference, 3.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 95.3ms\n",
      "Speed: 7.2ms preprocess, 95.3ms inference, 7.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 140.5ms\n",
      "Speed: 12.7ms preprocess, 140.5ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 115.0ms\n",
      "Speed: 8.8ms preprocess, 115.0ms inference, 2.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 139.3ms\n",
      "Speed: 6.6ms preprocess, 139.3ms inference, 4.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 194.3ms\n",
      "Speed: 15.5ms preprocess, 194.3ms inference, 6.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 87.8ms\n",
      "Speed: 6.8ms preprocess, 87.8ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 44.2ms\n",
      "Speed: 4.6ms preprocess, 44.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 38.3ms\n",
      "Speed: 4.6ms preprocess, 38.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 33.1ms\n",
      "Speed: 4.8ms preprocess, 33.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 34.7ms\n",
      "Speed: 4.8ms preprocess, 34.7ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.2ms\n",
      "Speed: 4.3ms preprocess, 31.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 37.3ms\n",
      "Speed: 4.6ms preprocess, 37.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.1ms\n",
      "Speed: 4.3ms preprocess, 38.1ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 280.8ms\n",
      "Speed: 5.9ms preprocess, 280.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 53.7ms\n",
      "Speed: 14.6ms preprocess, 53.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.1ms\n",
      "Speed: 4.3ms preprocess, 30.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 22.8ms\n",
      "Speed: 4.4ms preprocess, 22.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 24.2ms\n",
      "Speed: 3.7ms preprocess, 24.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.6ms\n",
      "Speed: 3.4ms preprocess, 21.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.1ms\n",
      "Speed: 2.8ms preprocess, 22.1ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.5ms\n",
      "Speed: 3.3ms preprocess, 22.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.1ms\n",
      "Speed: 2.8ms preprocess, 28.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.6ms\n",
      "Speed: 3.1ms preprocess, 22.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.0ms\n",
      "Speed: 3.2ms preprocess, 23.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.3ms\n",
      "Speed: 2.9ms preprocess, 25.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.1ms\n",
      "Speed: 3.1ms preprocess, 21.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.2ms\n",
      "Speed: 2.8ms preprocess, 22.2ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.8ms\n",
      "Speed: 4.5ms preprocess, 26.8ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.1ms\n",
      "Speed: 3.1ms preprocess, 22.1ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.9ms\n",
      "Speed: 3.3ms preprocess, 30.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.9ms\n",
      "Speed: 3.0ms preprocess, 27.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.3ms\n",
      "Speed: 3.0ms preprocess, 23.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.3ms\n",
      "Speed: 3.0ms preprocess, 23.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 34.0ms\n",
      "Speed: 3.0ms preprocess, 34.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.1ms\n",
      "Speed: 2.9ms preprocess, 21.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 28.7ms\n",
      "Speed: 3.0ms preprocess, 28.7ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.0ms\n",
      "Speed: 3.2ms preprocess, 23.0ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.8ms\n",
      "Speed: 3.2ms preprocess, 25.8ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.3ms\n",
      "Speed: 4.2ms preprocess, 27.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.9ms\n",
      "Speed: 3.0ms preprocess, 23.9ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.2ms\n",
      "Speed: 2.9ms preprocess, 26.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.0ms\n",
      "Speed: 3.2ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.5ms\n",
      "Speed: 3.3ms preprocess, 22.5ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 23.5ms\n",
      "Speed: 3.7ms preprocess, 23.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.4ms\n",
      "Speed: 3.1ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.2ms\n",
      "Speed: 3.0ms preprocess, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.3ms\n",
      "Speed: 3.9ms preprocess, 22.3ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.5ms\n",
      "Speed: 3.1ms preprocess, 22.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.1ms\n",
      "Speed: 3.3ms preprocess, 23.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.3ms\n",
      "Speed: 3.5ms preprocess, 31.3ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.4ms\n",
      "Speed: 3.3ms preprocess, 29.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 37.7ms\n",
      "Speed: 4.0ms preprocess, 37.7ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.4ms\n",
      "Speed: 3.6ms preprocess, 25.4ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.4ms\n",
      "Speed: 3.3ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.2ms\n",
      "Speed: 3.6ms preprocess, 21.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.7ms\n",
      "Speed: 2.8ms preprocess, 25.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.1ms\n",
      "Speed: 4.2ms preprocess, 21.1ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.9ms\n",
      "Speed: 2.9ms preprocess, 27.9ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 36.7ms\n",
      "Speed: 3.2ms preprocess, 36.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.5ms\n",
      "Speed: 2.9ms preprocess, 32.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.5ms\n",
      "Speed: 3.1ms preprocess, 32.5ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 28.3ms\n",
      "Speed: 3.1ms preprocess, 28.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.2ms\n",
      "Speed: 3.3ms preprocess, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.9ms\n",
      "Speed: 3.3ms preprocess, 32.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.7ms\n",
      "Speed: 3.0ms preprocess, 21.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 24.8ms\n",
      "Speed: 3.0ms preprocess, 24.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 24.8ms\n",
      "Speed: 2.9ms preprocess, 24.8ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.7ms\n",
      "Speed: 3.2ms preprocess, 21.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.0ms\n",
      "Speed: 2.9ms preprocess, 21.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 37.3ms\n",
      "Speed: 3.2ms preprocess, 37.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.6ms\n",
      "Speed: 2.9ms preprocess, 21.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 24.7ms\n",
      "Speed: 3.0ms preprocess, 24.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.4ms\n",
      "Speed: 4.5ms preprocess, 23.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 37.2ms\n",
      "Speed: 4.2ms preprocess, 37.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.8ms\n",
      "Speed: 2.9ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.0ms\n",
      "Speed: 2.9ms preprocess, 25.0ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.8ms\n",
      "Speed: 3.2ms preprocess, 22.8ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.2ms\n",
      "Speed: 3.2ms preprocess, 22.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.7ms\n",
      "Speed: 3.3ms preprocess, 27.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.2ms\n",
      "Speed: 4.3ms preprocess, 31.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.0ms\n",
      "Speed: 2.9ms preprocess, 30.0ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 22.3ms\n",
      "Speed: 2.9ms preprocess, 22.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.2ms\n",
      "Speed: 2.8ms preprocess, 23.2ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.5ms\n",
      "Speed: 2.8ms preprocess, 22.5ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 21.4ms\n",
      "Speed: 2.9ms preprocess, 21.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.9ms\n",
      "Speed: 3.4ms preprocess, 31.9ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.7ms\n",
      "Speed: 3.0ms preprocess, 27.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 53.3ms\n",
      "Speed: 4.0ms preprocess, 53.3ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.4ms\n",
      "Speed: 4.6ms preprocess, 29.4ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 28.4ms\n",
      "Speed: 3.7ms preprocess, 28.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.9ms\n",
      "Speed: 4.1ms preprocess, 21.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.9ms\n",
      "Speed: 2.9ms preprocess, 22.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.1ms\n",
      "Speed: 2.9ms preprocess, 23.1ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.1ms\n",
      "Speed: 2.8ms preprocess, 23.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.7ms\n",
      "Speed: 3.2ms preprocess, 23.7ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.1ms\n",
      "Speed: 2.8ms preprocess, 22.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.3ms\n",
      "Speed: 4.3ms preprocess, 22.3ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 22.1ms\n",
      "Speed: 2.7ms preprocess, 22.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.4ms\n",
      "Speed: 3.2ms preprocess, 26.4ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.0ms\n",
      "Speed: 3.4ms preprocess, 29.0ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 23.4ms\n",
      "Speed: 4.4ms preprocess, 23.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.6ms\n",
      "Speed: 3.7ms preprocess, 26.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 38.5ms\n",
      "Speed: 3.9ms preprocess, 38.5ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 96.5ms\n",
      "Speed: 4.3ms preprocess, 96.5ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 48.7ms\n",
      "Speed: 3.8ms preprocess, 48.7ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 39.7ms\n",
      "Speed: 4.5ms preprocess, 39.7ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 47.3ms\n",
      "Speed: 4.6ms preprocess, 47.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 47.2ms\n",
      "Speed: 4.6ms preprocess, 47.2ms inference, 3.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 55.7ms\n",
      "Speed: 6.2ms preprocess, 55.7ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 41.2ms\n",
      "Speed: 5.2ms preprocess, 41.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.8ms\n",
      "Speed: 3.8ms preprocess, 31.8ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 39.0ms\n",
      "Speed: 2.9ms preprocess, 39.0ms inference, 3.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 64.3ms\n",
      "Speed: 6.8ms preprocess, 64.3ms inference, 2.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 53.7ms\n",
      "Speed: 8.2ms preprocess, 53.7ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 56.4ms\n",
      "Speed: 6.0ms preprocess, 56.4ms inference, 4.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 65.9ms\n",
      "Speed: 9.6ms preprocess, 65.9ms inference, 2.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.2ms\n",
      "Speed: 5.7ms preprocess, 29.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 42.3ms\n",
      "Speed: 4.0ms preprocess, 42.3ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 33.4ms\n",
      "Speed: 3.6ms preprocess, 33.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 41.7ms\n",
      "Speed: 4.2ms preprocess, 41.7ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.6ms\n",
      "Speed: 4.4ms preprocess, 32.6ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.6ms\n",
      "Speed: 3.7ms preprocess, 30.6ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.3ms\n",
      "Speed: 3.0ms preprocess, 30.3ms inference, 2.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.4ms\n",
      "Speed: 3.3ms preprocess, 26.4ms inference, 3.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.3ms\n",
      "Speed: 3.8ms preprocess, 27.3ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.5ms\n",
      "Speed: 3.6ms preprocess, 30.5ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.4ms\n",
      "Speed: 3.6ms preprocess, 28.4ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.1ms\n",
      "Speed: 3.5ms preprocess, 30.1ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 32.2ms\n",
      "Speed: 4.7ms preprocess, 32.2ms inference, 1.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 34.8ms\n",
      "Speed: 4.0ms preprocess, 34.8ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 29.4ms\n",
      "Speed: 3.7ms preprocess, 29.4ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.7ms\n",
      "Speed: 4.0ms preprocess, 25.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.8ms\n",
      "Speed: 2.8ms preprocess, 23.8ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 34.5ms\n",
      "Speed: 3.3ms preprocess, 34.5ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 25.6ms\n",
      "Speed: 3.9ms preprocess, 25.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 35.8ms\n",
      "Speed: 3.0ms preprocess, 35.8ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 1 rotten, 21.4ms\n",
      "Speed: 2.8ms preprocess, 21.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 25.1ms\n",
      "Speed: 2.8ms preprocess, 25.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 24.0ms\n",
      "Speed: 3.0ms preprocess, 24.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 36.4ms\n",
      "Speed: 3.1ms preprocess, 36.4ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 22.1ms\n",
      "Speed: 2.7ms preprocess, 22.1ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.4ms\n",
      "Speed: 3.0ms preprocess, 27.4ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.7ms\n",
      "Speed: 3.0ms preprocess, 23.7ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.0ms\n",
      "Speed: 2.9ms preprocess, 23.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.2ms\n",
      "Speed: 3.1ms preprocess, 30.2ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 20.6ms\n",
      "Speed: 2.9ms preprocess, 20.6ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.4ms\n",
      "Speed: 2.8ms preprocess, 23.4ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.3ms\n",
      "Speed: 2.8ms preprocess, 21.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 21.3ms\n",
      "Speed: 3.6ms preprocess, 21.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.6ms\n",
      "Speed: 3.9ms preprocess, 31.6ms inference, 2.1ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 31.2ms\n",
      "Speed: 3.5ms preprocess, 31.2ms inference, 2.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.2ms\n",
      "Speed: 3.3ms preprocess, 30.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 33.5ms\n",
      "Speed: 4.4ms preprocess, 33.5ms inference, 1.5ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 26.3ms\n",
      "Speed: 3.1ms preprocess, 26.3ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 20.9ms\n",
      "Speed: 3.0ms preprocess, 20.9ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.4ms\n",
      "Speed: 3.4ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 5 healthys, 28.5ms\n",
      "Speed: 3.2ms preprocess, 28.5ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 25.7ms\n",
      "Speed: 3.1ms preprocess, 25.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 22.4ms\n",
      "Speed: 3.5ms preprocess, 22.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 24.3ms\n",
      "Speed: 3.3ms preprocess, 24.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 35.9ms\n",
      "Speed: 3.1ms preprocess, 35.9ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 30.1ms\n",
      "Speed: 2.9ms preprocess, 30.1ms inference, 2.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.0ms\n",
      "Speed: 2.8ms preprocess, 21.0ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 27.4ms\n",
      "Speed: 2.9ms preprocess, 27.4ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 27.3ms\n",
      "Speed: 2.9ms preprocess, 27.3ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 4 healthys, 33.7ms\n",
      "Speed: 4.0ms preprocess, 33.7ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 21.7ms\n",
      "Speed: 4.0ms preprocess, 21.7ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.8ms\n",
      "Speed: 4.4ms preprocess, 28.8ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.2ms\n",
      "Speed: 2.9ms preprocess, 23.2ms inference, 2.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.7ms\n",
      "Speed: 3.0ms preprocess, 28.7ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.6ms\n",
      "Speed: 3.9ms preprocess, 28.6ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.0ms\n",
      "Speed: 2.8ms preprocess, 25.0ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 28.2ms\n",
      "Speed: 2.8ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 23.9ms\n",
      "Speed: 3.0ms preprocess, 23.9ms inference, 1.4ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 2 healthys, 28.2ms\n",
      "Speed: 2.8ms preprocess, 28.2ms inference, 1.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 3 healthys, 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 1.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 24.9ms\n",
      "Speed: 2.9ms preprocess, 24.9ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.2ms\n",
      "Speed: 3.7ms preprocess, 21.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 25.0ms\n",
      "Speed: 3.0ms preprocess, 25.0ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.2ms\n",
      "Speed: 3.1ms preprocess, 21.2ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 34.6ms\n",
      "Speed: 3.2ms preprocess, 34.6ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.2ms\n",
      "Speed: 3.3ms preprocess, 21.2ms inference, 1.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 36.3ms\n",
      "Speed: 3.0ms preprocess, 36.3ms inference, 2.3ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.9ms\n",
      "Speed: 3.0ms preprocess, 20.9ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.3ms\n",
      "Speed: 3.1ms preprocess, 28.3ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.1ms\n",
      "Speed: 3.2ms preprocess, 22.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.3ms\n",
      "Speed: 3.0ms preprocess, 20.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.6ms\n",
      "Speed: 2.8ms preprocess, 29.6ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.8ms\n",
      "Speed: 3.1ms preprocess, 29.8ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.2ms\n",
      "Speed: 3.0ms preprocess, 25.2ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 20.7ms\n",
      "Speed: 2.8ms preprocess, 20.7ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.7ms\n",
      "Speed: 3.0ms preprocess, 28.7ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 1 healthy, 21.7ms\n",
      "Speed: 2.8ms preprocess, 21.7ms inference, 1.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.9ms\n",
      "Speed: 2.9ms preprocess, 25.9ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 39.2ms\n",
      "Speed: 3.0ms preprocess, 39.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.3ms\n",
      "Speed: 3.5ms preprocess, 25.3ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.8ms\n",
      "Speed: 3.0ms preprocess, 22.8ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 25.5ms\n",
      "Speed: 4.5ms preprocess, 25.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 30.8ms\n",
      "Speed: 5.5ms preprocess, 30.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.2ms\n",
      "Speed: 2.8ms preprocess, 21.2ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.5ms\n",
      "Speed: 3.1ms preprocess, 29.5ms inference, 1.2ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 23.7ms\n",
      "Speed: 3.3ms preprocess, 23.7ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.7ms\n",
      "Speed: 4.3ms preprocess, 28.7ms inference, 1.0ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.1ms\n",
      "Speed: 4.3ms preprocess, 21.1ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 26.8ms\n",
      "Speed: 3.6ms preprocess, 26.8ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 21.5ms\n",
      "Speed: 3.2ms preprocess, 21.5ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.0ms\n",
      "Speed: 3.6ms preprocess, 22.0ms inference, 0.7ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.8ms\n",
      "Speed: 2.9ms preprocess, 27.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.1ms\n",
      "Speed: 3.5ms preprocess, 29.1ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 27.2ms\n",
      "Speed: 4.1ms preprocess, 27.2ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.6ms\n",
      "Speed: 4.1ms preprocess, 29.6ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.0ms\n",
      "Speed: 4.2ms preprocess, 29.0ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 31.5ms\n",
      "Speed: 4.3ms preprocess, 31.5ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 28.8ms\n",
      "Speed: 4.3ms preprocess, 28.8ms inference, 0.9ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 29.4ms\n",
      "Speed: 4.1ms preprocess, 29.4ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.1ms\n",
      "Speed: 2.9ms preprocess, 22.1ms inference, 0.8ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "0: 480x640 (no detections), 22.0ms\n",
      "Speed: 4.4ms preprocess, 22.0ms inference, 0.6ms postprocess per image at shape (1, 3, 480, 640)\n",
      "\n",
      "Загальна кількість унікальних томатів по класах:\n",
      "good_10_40: 0\n",
      "good_40_70: 0\n",
      "healthy: 35\n",
      "unripe: 0\n",
      "rotten: 1\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "from ultralytics import YOLO\n",
    "from collections import defaultdict\n",
    "import numpy as np\n",
    "\n",
    "model = YOLO(\"C:/Users/Ki7/Yolo/runs/detect/train13/weights/best.pt\")\n",
    "\n",
    "class_names = ['good_10_40', 'good_40_70', 'healthy', 'unripe', 'rotten']\n",
    "\n",
    "cap = cv2.VideoCapture(\"video_tomato1.mp4\")\n",
    "width = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH))\n",
    "height = int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps = cap.get(cv2.CAP_PROP_FPS)\n",
    "\n",
    "out = cv2.VideoWriter(\"output2.avi\", cv2.VideoWriter_fourcc(*'XVID'), fps, (width, height))\n",
    "\n",
    "total_counts = defaultdict(int)\n",
    "\n",
    "# Зберігаємо центри вже знайдених об'єктів\n",
    "seen_objects = []\n",
    "\n",
    "# Порог для визнання нового об'єкта (пікселі)\n",
    "DIST_THRESHOLD = 50\n",
    "\n",
    "def is_new(center, label):\n",
    "    for obj in seen_objects:\n",
    "        if obj[\"label\"] == label:\n",
    "            prev_center = obj[\"center\"]\n",
    "            if np.linalg.norm(np.array(center) - np.array(prev_center)) < DIST_THRESHOLD:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        break\n",
    "\n",
    "    results = model(frame)[0]\n",
    "    frame_counts = defaultdict(int)\n",
    "\n",
    "    for result in results.boxes.data.tolist():\n",
    "        x1, y1, x2, y2, conf, cls = result\n",
    "        cls = int(cls)\n",
    "        if cls >= len(class_names):\n",
    "            continue\n",
    "\n",
    "        label = class_names[cls]\n",
    "        cx = int((x1 + x2) / 2)\n",
    "        cy = int((y1 + y2) / 2)\n",
    "        center = (cx, cy)\n",
    "\n",
    "        if is_new(center, label):\n",
    "            total_counts[label] += 1\n",
    "            seen_objects.append({\"center\": center, \"label\": label})\n",
    "\n",
    "        frame_counts[label] += 1\n",
    "\n",
    "        # Малюємо рамку\n",
    "        cv2.rectangle(frame, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)\n",
    "        cv2.putText(frame, label, (int(x1), int(y1)-10), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,255,0), 2)\n",
    "\n",
    "    # Показати кількість на кадрі\n",
    "    y0 = 30\n",
    "    for i, (label, count) in enumerate(frame_counts.items()):\n",
    "        text = f\"{label}: {count} (frame)\"\n",
    "        cv2.putText(frame, text, (10, y0 + i*25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    # Відображення\n",
    "    cv2.imshow(\"Detection\", frame)\n",
    "    out.write(frame)\n",
    "\n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "        break\n",
    "    # Показати кількість на кадрі\n",
    "    y0 = 30\n",
    "    for i, (label, count) in enumerate(frame_counts.items()):\n",
    "        text = f\"{label}: {count} (frame)\"\n",
    "        cv2.putText(frame, text, (10, y0 + i*25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (0,0,255), 2)\n",
    "\n",
    "    # 👇 Додаємо загальну кількість унікальних томатів\n",
    "    y1 = y0 + 25 * (len(frame_counts) + 1)\n",
    "    cv2.putText(frame, \"УНІКАЛЬНІ ТОМАТИ:\", (10, y1), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "    for i, (label, total) in enumerate(total_counts.items()):\n",
    "        text = f\"{label}: {total}\"\n",
    "        cv2.putText(frame, text, (10, y1 + (i + 1)*25), cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 0, 0), 2)\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Підсумковий результат\n",
    "print(\"\\nЗагальна кількість унікальних томатів по класах:\")\n",
    "for label in class_names:\n",
    "    print(f\"{label}: {total_counts[label]}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85bd8acb-e44b-45e1-9269-677828d14910",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9 (YOLO+GPU)",
   "language": "python",
   "name": "py39-yolo"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
